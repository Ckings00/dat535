{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.types import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder.appName(\"Cleaning\").getOrCreate())\n",
    "\n",
    "hadoop_rdd = spark.sparkContext.textFile(\"hdfs://namenode:9000/input\", minPartitions=120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to base the dataset on direct flights, aka Non-Stop flights.\n",
    "def filterNonStop(x):\n",
    "    row = x.split(\",\")\n",
    "    if row[8] == \"True\": return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['legId 0', 'searchDate 1', 'flightDate 2', 'startingAirport 3',\n",
    "#       'destinationAirport 4', 'travelDuration 5', 'elapsedDays 6', 'isBasicEconomy 7',\n",
    "#       'isNonStop 8', 'baseFare 9', 'totalFare 10', 'seatsRemaining 11',\n",
    "#       'totalTravelDistance 12', 'day_of_week 13', 'days_between_search_and_flight 14']\n",
    "\n",
    "# After removeCols, the columns are:\n",
    "#['searchDate 0', 'flightDate 1', 'startingAirport 2',\n",
    "#       'destinationAirport 3', 'travelDuration 4',\n",
    "#       'totalFare 5', 'totalTravelDistance 6', 'days_between_search_and_flight 7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeCols(x): \n",
    "    elements = []\n",
    "    row = x.split(\",\")\n",
    "    for index, element in enumerate(row):\n",
    "        #Excluding LegID 0, elapsedDays 6, IsBasicEconomy 7, isNonStop 8, baseFare 9,seatsRemaining 11, dayOfWeek 13\n",
    "        if index in [1, 2, 3, 4, 5, 10, 12, 14]:\n",
    "            elements.append(element)\n",
    "    return elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterFloatable(y):\n",
    "    row = y.split(\",\")\n",
    "    # We see that some totalTravelDistance values are empty, so we need to check for that.\n",
    "    # This is also pre-removed columns. Old indexes\n",
    "    totalFare = row[10]\n",
    "    totalTravelDistance = row[12]\n",
    "\n",
    "    try:\n",
    "        float(totalTravelDistance)\n",
    "        float(totalFare)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnvrtFloat(y): # totalFare 5 and totalTravelDistance 6\n",
    "    totalFare = y[5]\n",
    "    y[5] = float(totalFare)\n",
    "\n",
    "    totalTravelDistance = y[6]\n",
    "    y[6] = float(totalTravelDistance)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def cnvrtDate(y): # searchDate 0 and flightDate 1\n",
    "    searchDate = y[0]\n",
    "    searchDate = searchDate.split(\"-\")\n",
    "    searchDate = datetime.date(int(searchDate[0]), int(searchDate[1]), int(searchDate[2]))\n",
    "\n",
    "    flightDate = y[1]\n",
    "    flightDate = flightDate.split(\"-\")\n",
    "    flightDate = datetime.date(int(flightDate[0]), int(flightDate[1]), int(flightDate[2]))\n",
    "    \n",
    "    y[0] = searchDate\n",
    "    y[1] = flightDate\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnvrtInt(y): # days_between_search_and_flight 7\n",
    "    x = y[7] \n",
    "\n",
    "    days_between = int(x)\n",
    "\n",
    "    y[7] = days_between\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cnvrtDuration(y): # travelDuration 4\n",
    "    x = y[4]\n",
    "\n",
    "    houres, minutes = 0, 0\n",
    "\n",
    "    houres = r\"(\\d+)H\"\n",
    "    minutes = r\"(\\d+)M\"\n",
    "\n",
    "    houres_pattern = re.search(houres, x)\n",
    "    minutes_pattern = re.search(minutes, x)\n",
    "\n",
    "    if houres_pattern:\n",
    "        houres = int(houres_pattern.group(1))\n",
    "\n",
    "    if minutes_pattern:\n",
    "        minutes = int(minutes_pattern.group(1))\n",
    "     \n",
    "    y[4] = f\"{houres}:{minutes}\"\n",
    "    \n",
    "    return y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = hadoop_rdd.filter(filterNonStop)\n",
    "cnt = cnt.filter(filterFloatable)\n",
    "cnt = cnt.map(removeCols)\n",
    "cnt = cnt.map(cnvrtFloat)\n",
    "cnt = cnt.map(cnvrtDate)\n",
    "cnt = cnt.map(cnvrtInt)\n",
    "cnt = cnt.map(cnvrtDuration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = StructType([\n",
    "    StructField(\"searchDate\", DateType(), False), \n",
    "    StructField(\"flightDate\", DateType(), False),\n",
    "    StructField(\"startingAirport\", StringType(), False),\n",
    "    StructField(\"destinationAirport\", StringType(), False),\n",
    "    StructField(\"travelDuration\", StringType(), False),\n",
    "    StructField(\"totalFare\", FloatType(), False),\n",
    "    StructField(\"totalTravelDistance\", FloatType(), False),\n",
    "    StructField(\"days_between_search_and_flight\", IntegerType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(cnt, schema=table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.mode(\"overwrite\").csv(\"/project/data_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- searchDate: date (nullable = false)\n",
      " |-- flightDate: date (nullable = false)\n",
      " |-- startingAirport: string (nullable = false)\n",
      " |-- destinationAirport: string (nullable = false)\n",
      " |-- travelDuration: string (nullable = false)\n",
      " |-- totalFare: float (nullable = false)\n",
      " |-- totalTravelDistance: float (nullable = false)\n",
      " |-- days_between_search_and_flight: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+------------------+--------------+---------+-------------------+------------------------------+\n",
      "|searchDate|flightDate|startingAirport|destinationAirport|travelDuration|totalFare|totalTravelDistance|days_between_search_and_flight|\n",
      "+----------+----------+---------------+------------------+--------------+---------+-------------------+------------------------------+\n",
      "|2022-04-16|2022-04-17|            ATL|               CLT|          1:10|    398.6|              228.0|                             1|\n",
      "|2022-04-16|2022-04-17|            ATL|               CLT|          1:13|    398.6|              228.0|                             1|\n",
      "|2022-04-16|2022-04-17|            ATL|               DEN|          3:14|   296.61|             1207.0|                             1|\n",
      "|2022-04-16|2022-04-17|            ATL|               DEN|          3:21|   296.61|             1207.0|                             1|\n",
      "|2022-04-16|2022-04-17|            ATL|               DFW|          2:29|    202.6|              725.0|                             1|\n",
      "+----------+----------+---------------+------------------+--------------+---------+-------------------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
